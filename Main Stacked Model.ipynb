{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61d7ae-b145-488d-a193-3000ad456a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Model\n",
    "\n",
    "# STEP 1: INSTALL DEPENDENCIES FIRST\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, classification_report, brier_score_loss,\n",
    "    precision_score, f1_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "# from river import linear_model, preprocessing as river_preprocessing, metrics as river_metrics\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# STEP 2: LOAD DATA\n",
    "df = pd.read_csv(\"credit_risk_dataset.csv\")\n",
    "categorical = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n",
    "for col in categorical:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "\n",
    "df = df.dropna(subset=[\"loan_status\"])\n",
    "X = df.drop(columns=[\"loan_status\"])\n",
    "y = df[\"loan_status\"]\n",
    "\n",
    "numeric = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "X[numeric] = StandardScaler().fit_transform(X[numeric])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, stratify=y, random_state=42)\n",
    "X_train = pd.DataFrame(X_train).fillna(0).astype(np.float64)\n",
    "X_test = pd.DataFrame(X_test).fillna(0).astype(np.float64)\n",
    "\n",
    "# STEP 3: PSI CALCULATION\n",
    "def calculate_psi(expected, actual, buckets=10):\n",
    "    def scale_range(data): return (data - data.min()) / (data.max() - data.min())\n",
    "    psi_values = []\n",
    "    for col in expected.columns:\n",
    "        e, a = scale_range(expected[col]), scale_range(actual[col])\n",
    "        breakpoints = np.linspace(0, 1, buckets + 1)\n",
    "        expected_counts = np.histogram(e, bins=breakpoints)[0] / len(e)\n",
    "        actual_counts = np.histogram(a, bins=breakpoints)[0] / len(a)\n",
    "        psi = np.sum((expected_counts - actual_counts) * np.log((expected_counts + 1e-6) / (actual_counts + 1e-6)))\n",
    "        psi_values.append((col, psi))\n",
    "    return pd.DataFrame(psi_values, columns=[\"Feature\", \"PSI\"]).sort_values(by=\"PSI\", ascending=False)\n",
    "\n",
    "psi_df = calculate_psi(X_train, X_test)\n",
    "print(\"Top PSI drift features:\\n\", psi_df.head())\n",
    "\n",
    "# STEP 4: Y-DRIFT\n",
    "train_rate, test_rate = y_train.mean(), y_test.mean()\n",
    "print(f\"Train default rate: {train_rate:.4f}, Test default rate: {test_rate:.4f}, Diff: {abs(train_rate - test_rate):.4f}\")\n",
    "\n",
    "# STEP 5: ADVERSARIAL VALIDATION\n",
    "X_adv = pd.concat([X_train, X_test])\n",
    "y_adv = np.array([0]*len(X_train) + [1]*len(X_test))\n",
    "adv_model = LogisticRegression(max_iter=1000)\n",
    "adv_model.fit(X_adv, y_adv)\n",
    "adv_auc = roc_auc_score(y_adv, adv_model.predict_proba(X_adv)[:, 1])\n",
    "print(f\"Adversarial AUC (train vs test): {adv_auc:.4f}\")\n",
    "\n",
    "# STEP 6: OPTUNA FOR XGBOOST\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 5),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 5),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "        \"use_label_encoder\": False\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    aucs = []\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        preds = model.predict_proba(X_val)[:, 1]\n",
    "        aucs.append(roc_auc_score(y_val, preds))\n",
    "    return np.mean(aucs)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "xgb_best_params = study.best_params\n",
    "xgb_best_params[\"use_label_encoder\"] = False\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(**xgb_best_params)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# STEP 7: SHAP FEATURE SELECTION (TOP 30)\n",
    "explainer = shap.Explainer(xgb_model)\n",
    "shap_values = explainer(X_train)\n",
    "shap_mean = np.abs(shap_values.values).mean(axis=0)\n",
    "top_indices = np.argsort(shap_mean)[-30:]\n",
    "top_features = X_train.columns[top_indices]\n",
    "X_train = X_train[top_features].astype(np.float64)\n",
    "X_test = X_test[top_features].astype(np.float64)\n",
    "\n",
    "# STEP 8: STACKING + CALIBRATION\n",
    "base_models = [\n",
    "    ('lr', LogisticRegression(max_iter=1000, multi_class=\"ovr\")),\n",
    "    ('rf', RandomForestClassifier(n_estimators=150, max_depth=10)),\n",
    "    ('xgb', xgb_model)\n",
    "]\n",
    "meta = RidgeClassifier()\n",
    "stacked = StackingClassifier(estimators=base_models, final_estimator=meta, passthrough=True, n_jobs=-1)\n",
    "calibrated = CalibratedClassifierCV(estimator=stacked, method='sigmoid', cv=5)\n",
    "calibrated.fit(X_train.values, y_train.values)\n",
    "\n",
    "# STEP 9: METRICS + EXPORT\n",
    "y_proba = calibrated.predict_proba(X_test.values)[:, 1]\n",
    "y_pred = calibrated.predict(X_test.values)\n",
    "\n",
    "print(\"Final AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Brier Score:\", brier_score_loss(y_test, y_proba))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "submission = X_test.copy()\n",
    "submission[\"actual\"] = y_test.values\n",
    "submission[\"predicted\"] = y_pred\n",
    "submission[\"probability\"] = y_proba\n",
    "submission.to_csv(r\"C:\\Users\\maazj\\Downloads\\final_submission_stacked.csv\", index=False)\n",
    "\n",
    "# STEP 10: VERSIONING & RETRAINING\n",
    "if psi_df[\"PSI\"].max() > 0.2 or adv_auc > 0.6 or abs(train_rate - test_rate) > 0.05:\n",
    "    print(\"⚠ Drift detected — retraining model...\")\n",
    "    calibrated.fit(X_test.values, y_test.values)\n",
    "    joblib.dump(calibrated, r\"C:\\Users\\maazj\\Downloads\\model_v2_retrained.pkl\")\n",
    "else:\n",
    "    joblib.dump(calibrated, r\"‪C:\\IBA\\FDA\\Final\")\n",
    "\n",
    "# STEP 11: RIVER ONLINE TRAINING\n",
    "print(\"Running River Online Logistic Regression...\")\n",
    "river_pipeline = river_preprocessing.StandardScaler() | linear_model.LogisticRegression()\n",
    "river_auc = river_metrics.ROCAUC()\n",
    "\n",
    "for xi, yi in zip(X_test.to_dict(orient='records'), y_test):\n",
    "    pred = river_pipeline.predict_one(xi)\n",
    "    river_auc = river_auc.update(yi, pred)\n",
    "    river_pipeline = river_pipeline.learn_one(xi, yi)\n",
    "\n",
    "print(\"River Online AUC:\", river_auc.get())\n",
    "\n",
    "# STEP 12: OPTIONAL - PyCaret AutoML (Uncomment only if on Python 3.9–3.11)\n",
    "# from pycaret.classification import *\n",
    "# df_py = pd.DataFrame(X[top_features])\n",
    "# df_py['loan_status'] = y.values\n",
    "# setup(data=df_py, target='loan_status', silent=True, use_gpu=True)\n",
    "# best_model = compare_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
