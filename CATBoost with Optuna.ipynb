{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178ebb1a-e690-45a3-a6bf-9539e953a0ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshap\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "#Model 1\n",
    "# Catboost (Updated and Final)\n",
    "# STEP 1: Install libraries\n",
    "\n",
    "# STEP 2: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "from google.colab import files\n",
    "\n",
    "# STEP 3: Load Data\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/FDA Final Pres/credit_risk_dataset.csv\")\n",
    "df['person_emp_length'].fillna(df['person_emp_length'].median(), inplace=True)\n",
    "df['loan_int_rate'].fillna(df['loan_int_rate'].median(), inplace=True)\n",
    "\n",
    "X = df.drop(\"loan_status\", axis=1)\n",
    "y = df[\"loan_status\"]\n",
    "cat_features = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n",
    "\n",
    "# STEP 4: Advanced Optuna Objective with Cross-Validation\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 500, 1500),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 10),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-9, 10),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "        \"rsm\": trial.suggest_float(\"rsm\", 0.6, 1.0),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.5, 5.0),\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"AUC\",\n",
    "        \"verbose\": 0,\n",
    "        \"random_seed\": 42,\n",
    "        \"cat_features\": cat_features\n",
    "    }\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "    for train_idx, valid_idx in cv.split(X, y):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X_train, y_train, eval_set=(X_valid, y_valid), early_stopping_rounds=50)\n",
    "        preds = model.predict_proba(X_valid)[:, 1]\n",
    "        auc = roc_auc_score(y_valid, preds)\n",
    "        auc_scores.append(auc)\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=30, timeout=600)\n",
    "print(\"Best AUC:\", study.best_value)\n",
    "print(\"Best Parameters:\", study.best_params)\n",
    "\n",
    "# STEP 5: Train Final Model\n",
    "best_params = study.best_params\n",
    "best_params.update({\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"verbose\": 100,\n",
    "    \"random_seed\": 42,\n",
    "    \"cat_features\": cat_features\n",
    "})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# STEP 6: Evaluation\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "print(\"\\nâœ… Final Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# STEP 7: SHAP\n",
    "explainer = shap.Explainer(final_model)\n",
    "shap_values = explainer(X_test)\n",
    "shap.plots.beeswarm(shap_values, max_display=10)\n",
    "\n",
    "# STEP 8: PSI\n",
    "def calculate_psi(expected, actual, buckets=10):\n",
    "    breakpoints = np.percentile(expected, np.linspace(0, 100, buckets + 1))\n",
    "    breakpoints[-1] += 1e-6\n",
    "    expected_percents = np.histogram(expected, bins=breakpoints)[0] / len(expected)\n",
    "    actual_percents = np.histogram(actual, bins=breakpoints)[0] / len(actual)\n",
    "    psi_values = []\n",
    "    for e, a in zip(expected_percents, actual_percents):\n",
    "        if e == 0 or a == 0:\n",
    "            psi_values.append(0)\n",
    "        else:\n",
    "            psi_values.append((e - a) * np.log(e / a))\n",
    "    return np.sum(psi_values)\n",
    "\n",
    "# Simulate drift\n",
    "X_drifted = X_test.copy()\n",
    "X_drifted['loan_intent'] = np.random.choice(X['loan_intent'].unique(), size=len(X_drifted), p=[0.25, 0.15, 0.15, 0.15, 0.15, 0.15])\n",
    "X_drifted['loan_int_rate'] += np.random.normal(loc=2.0, scale=1.0, size=len(X_drifted))\n",
    "expected_scores = final_model.predict_proba(X_test)[:, 1]\n",
    "drifted_scores = final_model.predict_proba(X_drifted)[:, 1]\n",
    "psi_score = calculate_psi(expected_scores, drifted_scores, buckets=10)\n",
    "print(f\"\\nðŸ“Š Population Stability Index (PSI): {psi_score:.4f}\")\n",
    "\n",
    "# STEP 9: Save & Download\n",
    "results_df = X_test.copy()\n",
    "results_df[\"actual\"] = y_test.values\n",
    "results_df[\"predicted\"] = y_pred\n",
    "results_df[\"predicted_prob\"] = y_prob\n",
    "results_df.to_csv(\"zest_advanced_model_predictions.csv\", index=False)\n",
    "files.download(\"zest_advanced_model_predictions.csv\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay\n",
    "\n",
    "# CONFUSION MATRIX\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Default\", \"Default\"], yticklabels=[\"No Default\", \"Default\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC CURVE\n",
    "RocCurveDisplay.from_predictions(y_test, y_proba)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# PRECISION-RECALL CURVE\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_proba)\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# XGBOOST FEATURE IMPORTANCE (plotting top 30)\n",
    "plt.figure(figsize=(10, 8))\n",
    "xgb.plot_importance(xgb_model, max_num_features=30, importance_type='gain', height=0.6)\n",
    "plt.title(\"XGBoost Feature Importance (Gain)\")\n",
    "plt.show()\n",
    "\n",
    "# SHAP SUMMARY PLOT\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\", max_display=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1882db-d185-4c5c-b6b6-02f3151e923f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
