{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60b701-ec4a-48a1-85c3-e9bdad216789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Install Libraries\n",
    "!pip install shap --quiet\n",
    "!pip install --upgrade scikit-learn --quiet\n",
    "\n",
    "# STEP 2: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from google.colab import files\n",
    "\n",
    "# STEP 3: Load and Preprocess Data\n",
    "df = pd.read_csv(\"/content/credit_risk_dataset.csv\")\n",
    "df['person_emp_length'].fillna(df['person_emp_length'].median(), inplace=True)\n",
    "df['loan_int_rate'].fillna(df['loan_int_rate'].median(), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n",
    "df[categorical_cols] = df[categorical_cols].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(\"loan_status\", axis=1)\n",
    "y = df[\"loan_status\"]\n",
    "\n",
    "# STEP 4: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# STEP 5: Hyperparameter Tuning with RandomizedSearchCV\n",
    "param_dist = {\n",
    "    \"n_estimators\": [50, 100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.3, 1.0],\n",
    "    \"base_estimator__max_depth\": [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "base_est = DecisionTreeClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator=base_est)\n",
    "\n",
    "search = RandomizedSearchCV(ada, param_distributions=param_dist, n_iter=20,\n",
    "                            scoring=\"roc_auc\", cv=3, verbose=1, n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "model = search.best_estimator_\n",
    "\n",
    "# STEP 6: Evaluate Model\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n‚úÖ Evaluation on Test Data:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# STEP 7: Feature Importance using Permutation\n",
    "perm = permutation_importance(model, X_test, y_test, scoring='roc_auc', n_repeats=10, random_state=42)\n",
    "sorted_idx = perm.importances_mean.argsort()[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(X.columns[sorted_idx][:10][::-1], perm.importances_mean[sorted_idx][:10][::-1])\n",
    "plt.title(\"Top 10 Feature Importances (Permutation)\")\n",
    "plt.xlabel(\"Mean Decrease in AUC\")\n",
    "plt.show()\n",
    "\n",
    "# STEP 8: Simulate Drift\n",
    "X_drifted = X_test.copy()\n",
    "X_drifted['loan_intent'] = np.random.choice(X['loan_intent'].unique(), size=len(X_drifted), p=[0.25, 0.15, 0.15, 0.15, 0.15, 0.15])\n",
    "X_drifted['loan_int_rate'] += np.random.normal(loc=2.0, scale=1.0, size=len(X_drifted))\n",
    "\n",
    "# STEP 9: PSI Calculation\n",
    "def calculate_psi(expected, actual, buckets=10):\n",
    "    breakpoints = np.percentile(expected, np.linspace(0, 100, buckets + 1))\n",
    "    breakpoints[-1] += 1e-6\n",
    "    expected_percents = np.histogram(expected, bins=breakpoints)[0] / len(expected)\n",
    "    actual_percents = np.histogram(actual, bins=breakpoints)[0] / len(actual)\n",
    "    psi = np.sum((expected_percents - actual_percents) * np.log((expected_percents + 1e-8) / (actual_percents + 1e-8)))\n",
    "    return psi\n",
    "\n",
    "score_before = model.predict_proba(X_test)[:, 1]\n",
    "score_drifted = model.predict_proba(X_drifted)[:, 1]\n",
    "psi_score = calculate_psi(score_before, score_drifted)\n",
    "print(f\"\\nüìä PSI (Prediction Drift): {psi_score:.4f}\")\n",
    "\n",
    "# STEP 10: Auto-Retrain if PSI > 0.2\n",
    "if psi_score > 0.2:\n",
    "    print(\"üö® Drift detected. Retraining model on drifted data...\")\n",
    "    model.fit(X_drifted, y_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    print(\"üîÅ Retrained Model Evaluation:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "else:\n",
    "    print(\"‚úÖ No significant drift. Model remains valid.\")\n",
    "\n",
    "# STEP 11: Save and Download Results\n",
    "results_df = X_test.copy()\n",
    "results_df[\"actual\"] = y_test.values\n",
    "results_df[\"predicted\"] = y_pred\n",
    "results_df[\"predicted_prob\"] = y_prob\n",
    "results_df.to_csv(\"adaboost_predictions.csv\", index=False)\n",
    "files.download(\"adaboost_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
